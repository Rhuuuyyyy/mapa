# AnÃ¡lise de Custos Altos - MAPA SaaS Azure

**Data:** 22 de Novembro de 2025
**Custo Mensal:** R$ 100,00 (50% App Service + 50% Banco de Dados)

---

## ðŸ”´ PROBLEMAS CRÃTICOS IDENTIFICADOS

### 1. **Queries SEM PaginaÃ§Ã£o** - IMPACTO ALTO ðŸ’°ðŸ’°ðŸ’°

VÃ¡rios endpoints carregam TODOS os dados de uma vez, sem limite:

| Endpoint | Arquivo | Linha | Problema |
|----------|---------|-------|----------|
| `GET /companies` | `user.py` | 224 | `.all()` sem limit |
| `GET /products` | `user.py` | 365 | `.all()` sem limit |
| `GET /catalog` | `user.py` | 451 | `.all()` sem limit (empresas + produtos) |
| `GET /uploads` | `user.py` | 734 | `.all()` sem limit |
| `GET /reports` | `user.py` | 1124 | `.all()` sem limit |

**Impacto:**
- **Banco:** Queries pesadas consomem muita CPU/memÃ³ria (DTUs)
- **App:** SerializaÃ§Ã£o de muitos objetos consome memÃ³ria
- **Rede:** TransferÃªncia de dados desnecessÃ¡ria

**Exemplo:** Se um usuÃ¡rio tem 10.000 produtos, toda vez que acessar o catÃ¡logo, vai:
1. Fazer query de 10.000 linhas no banco
2. Carregar 10.000 objetos na memÃ³ria do app
3. Serializar 10.000 produtos para JSON
4. Transferir megabytes de dados

---

### 2. **Pool de ConexÃµes Pequeno** - IMPACTO MÃ‰DIO ðŸ’°ðŸ’°

```python
# database.py linha 19
pool_size=5,
max_overflow=10,
# Total: apenas 15 conexÃµes simultÃ¢neas
```

**Problema:**
- Com mÃºltiplos usuÃ¡rios fazendo requests, o pool se esgota
- Novas conexÃµes ficam aguardando
- Azure PostgreSQL cobra por conexÃ£o ativa
- Pode estar abrindo/fechando conexÃµes constantemente (overhead)

**Sintomas:**
- Timeout em requests
- Database connection errors
- Custo alto de banco mesmo com poucas queries

---

### 3. **Processamento SÃ­ncrono Pesado** - IMPACTO ALTO ðŸ’°ðŸ’°ðŸ’°

```python
# user.py linha 1076-1077
processor = MAPAProcessor(db, current_user.id)
result = processor.process_uploads(uploads)  # SÃNCRONO!
```

**Problema:**
- Processa TODOS os XMLs do perÃ­odo de forma sÃ­ncrona
- Bloqueia o worker do Gunicorn/Uvicorn
- Se processar 100 XMLs, a request fica travada por minutos
- Azure App Service cobra por tempo de CPU

**Impacto:**
- Workers bloqueados = precisa de mais workers
- Mais workers = maior SKU do App Service = mais caro
- Se tiver apenas 2 workers e 2 requests pesadas, app trava

---

### 4. **Falta de Cache** - IMPACTO MÃ‰DIO ðŸ’°ðŸ’°

**NÃ£o hÃ¡ cache em lugar nenhum:**
- CatÃ¡logo Ã© buscado do banco toda vez
- Companies/Products sÃ£o buscados repetidamente
- Sem Redis ou cache em memÃ³ria

**Exemplo:**
Se um usuÃ¡rio acessa a tela de upload 100x por dia:
- 100 queries para buscar companies
- 100 queries para buscar products
- 100 queries desnecessÃ¡rias!

---

### 5. **Queries N+1 Potenciais** - IMPACTO MÃ‰DIO ðŸ’°

```python
# user.py linha 442-451
companies = db.query(models.Company)...
return [
    {
        "company_id": c.id,
        "products": db.query(models.Product).filter(...).all()  # N+1!
    }
]
```

**Problema:**
- 1 query para pegar companies
- N queries para pegar products de cada company
- Com 100 companies = 101 queries ao invÃ©s de 2!

---

### 6. **Logs Excessivos em Debug** - IMPACTO BAIXO ðŸ’°

```python
# database.py linha 22
echo=settings.debug  # SQL queries no log
```

Se `DEBUG=True` em produÃ§Ã£o:
- Loga TODA query SQL
- Consome I/O de disco
- Pode gerar gigabytes de logs
- Azure cobra por armazenamento

---

## ðŸ“Š ESTIMATIVA DE IMPACTO

### CenÃ¡rio Atual (100 usuÃ¡rios ativos/dia):

| OperaÃ§Ã£o | FrequÃªncia | Queries/Op | Total Queries/Dia |
|----------|------------|------------|-------------------|
| Listar CatÃ¡logo | 100x | 100-1000 | 10.000-100.000 |
| Listar Uploads | 200x | 1 | 200 |
| Gerar RelatÃ³rio | 50x | 500+ | 25.000+ |
| **TOTAL** | - | - | **~35.000-125.000** |

### Custo por Componente:

**Azure Database for PostgreSQL (R$ 50/mÃªs):**
- Basic tier provavelmente
- 1-2 vCores
- Gasta muito em DTU por queries pesadas
- ConexÃµes ativas custam recursos

**App Service (R$ 50/mÃªs):**
- Provavelmente B1 ou B2 tier
- Workers ficam bloqueados em processamento
- Precisa de tier maior por causa de workers travados

---

## âœ… SOLUÃ‡Ã•ES RECOMENDADAS

### PRIORIDADE 1 (Economia estimada: 40-60%)

#### 1.1 Adicionar PaginaÃ§Ã£o em TODOS os endpoints

```python
# Antes
@router.get("/companies")
async def list_companies(db: Session = Depends(get_db), ...):
    companies = db.query(models.Company).all()  # RUIM

# Depois
@router.get("/companies")
async def list_companies(
    page: int = 1,
    page_size: int = 50,  # Limite padrÃ£o
    db: Session = Depends(get_db),
    ...
):
    skip = (page - 1) * page_size
    companies = db.query(models.Company)\
        .offset(skip)\
        .limit(page_size)\
        .all()

    total = db.query(models.Company).count()

    return {
        "items": companies,
        "total": total,
        "page": page,
        "page_size": page_size,
        "total_pages": (total + page_size - 1) // page_size
    }
```

#### 1.2 Otimizar Pool de ConexÃµes

```python
# database.py
engine = create_engine(
    settings.database_url,
    pool_pre_ping=True,
    pool_size=10,        # Aumentar para 10
    max_overflow=20,     # Aumentar para 20
    pool_recycle=300,    # Reciclar a cada 5min (menos que antes)
    echo=False,          # NUNCA em produÃ§Ã£o
    pool_timeout=30,     # Timeout para pegar conexÃ£o
)
```

#### 1.3 Processar XMLs de Forma AssÃ­ncrona

```python
# Usar background tasks ou fila (Celery/Redis)
from fastapi import BackgroundTasks

@router.post("/generate-report")
async def generate_report(
    background_tasks: BackgroundTasks,
    request: schemas.ReportGenerateRequest,
    ...
):
    # Iniciar processamento em background
    background_tasks.add_task(process_report_async, uploads, user_id)

    return {
        "message": "RelatÃ³rio sendo processado. VocÃª receberÃ¡ uma notificaÃ§Ã£o."
    }
```

### PRIORIDADE 2 (Economia estimada: 20-30%)

#### 2.1 Adicionar Cache com Redis

```python
import redis
from functools import lru_cache

redis_client = redis.Redis(host='localhost', port=6379, decode_responses=True)

@router.get("/catalog")
async def get_catalog(current_user: models.User = Depends(...)):
    cache_key = f"catalog:user:{current_user.id}"

    # Tentar cache primeiro
    cached = redis_client.get(cache_key)
    if cached:
        return json.loads(cached)

    # Se nÃ£o tem cache, buscar do banco
    catalog = db.query(...).all()

    # Salvar no cache por 5 minutos
    redis_client.setex(cache_key, 300, json.dumps(catalog))

    return catalog
```

#### 2.2 Resolver Queries N+1 com Eager Loading

```python
from sqlalchemy.orm import joinedload

# Antes (N+1)
companies = db.query(models.Company).all()
for company in companies:
    products = company.products  # Query extra!

# Depois (1 query)
companies = db.query(models.Company)\
    .options(joinedload(models.Company.products))\
    .all()
```

### PRIORIDADE 3 (Economia estimada: 10-20%)

#### 3.1 Adicionar Ãndices no Banco

```sql
-- Ãndices para queries frequentes
CREATE INDEX idx_uploads_user_period ON xml_uploads(user_id, period);
CREATE INDEX idx_reports_user_period ON reports(user_id, report_period);
CREATE INDEX idx_products_company_name ON products(company_id, product_name);
```

#### 3.2 Configurar CompressÃ£o de Responses

```python
# main.py
from fastapi.middleware.gzip import GZipMiddleware

app.add_middleware(GZipMiddleware, minimum_size=1000)
```

---

## ðŸŽ¯ PLANO DE AÃ‡ÃƒO IMEDIATO

### Semana 1 (ReduÃ§Ã£o ~50% do custo):
1. âœ… Adicionar paginaÃ§Ã£o em todos os endpoints
2. âœ… Aumentar pool de conexÃµes
3. âœ… Garantir DEBUG=False em produÃ§Ã£o
4. âœ… Limitar rate limiting mais agressivo

### Semana 2 (ReduÃ§Ã£o adicional ~20%):
5. âœ… Implementar cache Redis bÃ¡sico
6. âœ… Otimizar queries N+1
7. âœ… Adicionar Ã­ndices no banco

### Semana 3 (ReduÃ§Ã£o adicional ~10%):
8. âœ… Processamento assÃ­ncrono de relatÃ³rios
9. âœ… CompressÃ£o de responses
10. âœ… Monitoramento de queries lentas

---

## ðŸ’¡ DICAS EXTRAS

### Verificar Tier do App Service
```bash
# Ver o SKU atual
az webapp show --name mapa-app-clean-8270 --resource-group your-rg \
  --query "sku.name"
```

Se estiver em **B2** ou superior, pode reduzir para **B1** apÃ³s otimizaÃ§Ãµes.

### Monitorar Queries Lentas

```python
# Adicionar ao database.py
import logging
from sqlalchemy import event

@event.listens_for(Engine, "before_cursor_execute")
def before_cursor_execute(conn, cursor, statement, parameters, context, executemany):
    conn.info.setdefault('query_start_time', []).append(time.time())

@event.listens_for(Engine, "after_cursor_execute")
def after_cursor_execute(conn, cursor, statement, parameters, context, executemany):
    total = time.time() - conn.info['query_start_time'].pop(-1)
    if total > 1.0:  # Queries > 1 segundo
        logger.warning(f"SLOW QUERY ({total:.2f}s): {statement}")
```

---

## ðŸ“ˆ RESULTADO ESPERADO

Com todas as otimizaÃ§Ãµes implementadas:

| Componente | Custo Atual | Custo Estimado | Economia |
|------------|-------------|----------------|----------|
| App Service | R$ 50 | R$ 25-30 | 40-50% |
| Database | R$ 50 | R$ 20-25 | 50-60% |
| **TOTAL** | **R$ 100** | **R$ 45-55** | **45-55%** |

---

**Quer que eu implemente essas otimizaÃ§Ãµes agora?**
